{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MadridCohort_Video_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antwandaher/opl/blob/master/Video_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoWXOiJ-RE4i",
        "colab_type": "text"
      },
      "source": [
        "## Download Videos from YouTube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzCnqRANRJVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pytube"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROBo7TTcRLfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytube"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm4XtsM5RXKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_url='https://www.youtube.com/watch?v=jDC_DAXBG7M'\n",
        "\n",
        "youtube=pytube.YouTube(video_url)\n",
        "video=youtube.streams.first()\n",
        "video.download(path_to_drive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcmjk6JoRZMP",
        "colab_type": "text"
      },
      "source": [
        "## Settings and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39523qV_4xt_",
        "colab_type": "code",
        "outputId": "279c252b-2b0a-47f7-9076-4f585c37e4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs5Am2qX41Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *\n",
        "from zipfile import ZipFile \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A91yoEtg53_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41XLLjhX55ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_drive=Path('/gdrive/My Drive/MadridCohort/Project_damage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBr7VXjp6C-7",
        "colab_type": "code",
        "outputId": "13c676a8-cd67-4feb-d214-c87e235841b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2L34dYMEA-n",
        "colab_type": "text"
      },
      "source": [
        "##Helper Functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8O_121N_hMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Relevant Librarires\n",
        "from fastai.callbacks.hooks import *\n",
        "from google.colab.patches import cv2_imshow\n",
        "#!curl -o logo.png https://colab.research.google.com/img/colab_favicon_256px.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW71rIYaVZ8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Function that generates de 7x7 heatmap array, y is the value of the category we want ot highlight (y=1 corresponds to positive damage in our case)\n",
        "\n",
        "def hm_array(img,y):\n",
        "  xb,_ = data.one_item(img)\n",
        "  xb_im = Image(data.denorm(xb)[0])\n",
        "  xb = xb.cuda()\n",
        "  m=learn.model.eval()\n",
        "  cat=y\n",
        "  with hook_output(m[0]) as hook_a: \n",
        "    with hook_output(m[0], grad=True) as hook_g:\n",
        "      preds = m(xb)\n",
        "      preds[0,int(cat)].backward()\n",
        "  acts = hook_a.stored[0].cpu()\n",
        "  grad = hook_g.stored[0][0].cpu()\n",
        "\n",
        "  grad_chan = grad.mean(1).mean(1)\n",
        "  mult = (acts*grad_chan[...,None,None]).mean(0)\n",
        "\n",
        "  return mult\n",
        "\n",
        "\n",
        "# Calculating list of coordinates of activated pixels (points with values equal to 1)\n",
        "def get_coords(img_path):\n",
        "   img=open_image(img_path) #Opening image\n",
        "   img_array_=hm_array(img,1)  #Creating array from image\n",
        "   # Calculating widht and height of original image for re-scaling\n",
        "   img_h=img.shape[1]\n",
        "   img_w=img.shape[2]\n",
        "   img_array = cv2.resize(img_array_.numpy(), (img_w, img_h))  # resize the Gradcam tensor\n",
        "   # Calculating mean and standard deviation of heatmap which will be used to pick up activated part of image\n",
        "   img_mean=np.mean(img_array)\n",
        "   img_sd=np.std(img_array)\n",
        "   # Picking up (1) most activated region of the heatmap. This could be further optimized\n",
        "   img_array[img_array <=img_mean+img_sd]=0\n",
        "   img_array[img_array > img_mean+img_sd]=1\n",
        "   # Picking up (1) most activated region of the heatmap. This could be further optimized\n",
        "   active_px = np.argwhere(img_array!=0)\n",
        "   active_px = active_px[:,[1,0]]\n",
        "   x,y,w,h = cv2.boundingRect(active_px)\n",
        "   vertices=[(x,y),(x+w,y+h)]\n",
        "   return vertices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg-NdkgqlZ8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Drawing rectangle and text\n",
        "\n",
        "def drawing_box(path_in,path_out,fname, color,label):\n",
        "  '''\n",
        "\n",
        "  path_in: string\n",
        "  path_out: tring\n",
        "  '''\n",
        "  path_in=str(path_in)+'/'\n",
        "  path_out=str(path_out)+'/'\n",
        "  \n",
        "  rgb = ()\n",
        "  \n",
        "  if 'red' in color:\n",
        "    rgb=(0, 0, 255)\n",
        "    pos=20\n",
        "  elif 'blue' in color:\n",
        "    rgb=(255, 0, 0)\n",
        "    pos=40\n",
        "  else:\n",
        "    rgb=(0, 255, 0)\n",
        "    pos=60\n",
        "    \n",
        "  img_path=path_in+fname #cv2 imread function requires path to be entered as a string\n",
        "  img_test=cv2.imread(img_path)\n",
        "\n",
        "  ## Saving coords\n",
        "\n",
        "  coords_alex=get_coords(img_path)\n",
        "  rect=cv2.rectangle(img_test,coords_alex[0],coords_alex[1],rgb, 5)\n",
        "  rect=cv2.putText(img_test, label, (20, img_test.shape[0]-pos), cv2.FONT_HERSHEY_TRIPLEX, 2, rgb, 2)\n",
        "  cv2.imwrite(path_out+'/'+fname,rect)\n",
        "\n",
        "  return coords_alex\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH5x74p3D875",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_heatmap(path_in,path_out,fname,y):\n",
        "  path_in=str(path_in)+'/'\n",
        "  path_out=str(path_out)+'/'\n",
        "  img_path=path_in+fname\n",
        "  img=open_image(img_path) #Opening image\n",
        "  img_h=img.shape[1]\n",
        "  img_w=img.shape[2]\n",
        "  xb,_ = data.one_item(img)\n",
        "  xb_im = Image(data.denorm(xb)[0])\n",
        "  xb = xb.cuda()\n",
        "  m=learn.model.eval()\n",
        "  cat=y\n",
        "  with hook_output(m[0]) as hook_a:\n",
        "   with hook_output(m[0], grad=True) as hook_g:\n",
        "     preds = m(xb)\n",
        "     preds[0,int(cat)].backward()\n",
        "  acts = hook_a.stored[0].cpu()\n",
        "  grad = hook_g.stored[0][0].cpu()\n",
        "  grad_chan = grad.mean(1).mean(1)\n",
        "  hm = (acts*grad_chan[...,None,None]).mean(0)\n",
        "  _,ax = plt.subplots()\n",
        "  img.show(ax)\n",
        "  ax.imshow(hm, alpha=0.6, extent=(0,img_w,img_h,0),\n",
        "             interpolation='bilinear', cmap='magma');\n",
        "  ## Removing white space around image\n",
        "  plt.gca().set_axis_off()\n",
        "  plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0,\n",
        "           hspace = 0, wspace = 0)\n",
        "  plt.margins(0,0)\n",
        "  plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
        "  plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
        "  plt.savefig(path_out+'/'+fname,bbox_inches = 'tight',\n",
        "   pad_inches = 0)\n",
        "  plt.close()\n",
        "  #plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqvYrBnC6Iqq",
        "colab_type": "text"
      },
      "source": [
        "##Get Preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QueTHucS6Kjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_frames(learn, label_pos, label_neg, threshold=0.95):\n",
        "  prob,cat = learn.get_preds(DatasetType.Test)\n",
        "  preds_ = np.argmax(prob,1)\n",
        "  preds__=[x.item() for x in preds_]\n",
        "  label=[label_pos if x==1  else label_neg for x in preds__]\n",
        "  idx=[x for x in learn.data.test_ds.items]\n",
        "  final=[prob[x][preds__[x]].item() for x in range(len(preds__))]\n",
        "\n",
        "  # We add all this info in a dataframe\n",
        "  total=[]\n",
        "  for i in range(len(preds__)):\n",
        "\n",
        "    frame=int(str(idx[i])[27:-4])\n",
        "    total.append([idx[i],final[i],label[i],frame])\n",
        "\n",
        "  columns = ['name','prob','label','indx']\n",
        "  total = pd.DataFrame(total, columns=columns)\n",
        "  total.sort_values(by='indx',axis=0, inplace=True)\n",
        "  \n",
        "  total_threshold=total[total['prob']>threshold]\n",
        "  total_threshold=total_threshold[total_threshold['label'].isin([label_pos])] \n",
        "  \n",
        "  df_threshold=total_threshold.copy()\n",
        "  df_threshold.drop(labels=['prob','indx'],axis=1,inplace=True)\n",
        "  df_threshold['name']=[str(x)[1:]for x in df_threshold['name']]\n",
        "  df_threshold.head()\n",
        "  return total_threshold, df_threshold\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaFhy1yyIM3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_bunch(df_threshold):\n",
        "  return (ImageList.from_df(path='/',df=df_threshold)\n",
        "        .split_none()\n",
        "        .label_empty()\n",
        "        .transform(tfms=[[],[]],size=(299,299))\n",
        "        .databunch(bs=32)).normalize(imagenet_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp4iIW67qZug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_on_learner(total_threshold, box_color, label_pos):\n",
        "  for index, row in total_threshold.iterrows():\n",
        "      fname=str(row['name'])\n",
        "      fname=fname[22:]\n",
        "      drawing_box(p_video,p_video_out,fname, box_color, label_pos)\n",
        "      #save_heatmap(p_video,p_video_out,fname,1) ## last sets the label of the category we want to activate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhnX19Xz8pMX",
        "colab_type": "text"
      },
      "source": [
        "##Extract Video Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDw4_J5J7yTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for reset\n",
        "#!rm -rf damage/video\n",
        "!rm -rf damage/video_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzXEBcLK9j-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "15e7f17e-9e5b-49fa-a0b7-60dc5013de4c"
      },
      "source": [
        "# # Input and output setup\n",
        "p_video = Path('/content/damage/video/')\n",
        "p_video_out=Path('/content/damage/video_output/')\n",
        "\n",
        "# p_video.mkdir()\n",
        "# p_video_out.mkdir()\n",
        "    \n",
        "!mkdir damage\n",
        "!mkdir damage/video\n",
        "!mkdir damage/video_output\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘damage’: File exists\n",
            "mkdir: cannot create directory ‘damage/video’: File exists\n",
            "mkdir: cannot create directory ‘damage/video_output’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TBbsdb_8tn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videoFile=  path_to_drive/'Video_challenge/box_madrid_cohort.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(str(videoFile))   # capturing the video from the given path\n",
        "frameRate = 3\n",
        "count = 0\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"frame%d.png\" % count;count+=1\n",
        "        cv2.imwrite(str(p_video/filename), frame)\n",
        "cap.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rkR35LJ91FB",
        "colab_type": "code",
        "outputId": "d2d98db0-15f1-48bb-ea80-b9b6304e0a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "output_count = sum('.png' in x for x in os.listdir(p_video))    # list(filter(lambda x: '.jpg' in x, os.listdir(p_video))).length\n",
        "print (\"Done! Output .png count: {} files\".format(output_count))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done! Output .png count: 914 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_IjSrt7tYIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -a /content/damage/video/. /content/damage/video_output/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJTmum_iQiaJ",
        "colab_type": "text"
      },
      "source": [
        "##Load Video Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-8T2_SKQnuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " learner_list = [\n",
        "#      {'folder': 'model', 'name':'RN34_Callback.pkl', 'label':'Structure_Damage', 'label_pos': 'positive', 'label_neg': 'negative', 'fp_16': False, 'box-color':'red'},\n",
        "#      {'folder': 'models_for_video', 'name':'platform-demo4_week4_models_Water-damage.pkl', 'label':'Water_Damage', 'label_pos': 'water_d', 'label_neg': 'no_water_d', 'fp_16': False, 'box-color':'blue'},\n",
        "     {'folder': 'models_for_video', 'name':'overgrown_landscape_SF.pkl', 'label':'Overgrown_Landscape', 'label_pos': 'overgrown', 'label_neg': 'undergrown', 'fp_16': True, 'box-color':'green'},\n",
        "     {'folder': 'models_for_video', 'name':'platform-demo4_week4_models_dead_landscape.pkl', 'label':'Dead_Landscape', 'label_pos': 'dead', 'label_neg': 'healthy', 'fp_16': False, 'box-color':'green'}\n",
        "  ]\n",
        "#     \n",
        "# learn = load_learner(path_to_drive/'model/','RN34_Callback.pkl',test=ImageList.from_folder(p_video))\n",
        "# learn2 = load_learner(path_to_drive/'model/','RN34_Callback.pkl',test=ImageList.from_folder(p_video))\n",
        "\n",
        "#learner_list = [{'folder': 'models_for_video', 'name':'platform-demo4_week4_models_dead_landscape.pkl', 'label':'Dead_Landscape', 'label_pos': 'dead', 'label_neg': 'healthy', 'fp_16': False, 'box-color':'green'}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a80KdmThKpst",
        "colab_type": "code",
        "outputId": "21ed48e7-d2ea-4099-bdf0-685bc061a0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "model_stack, success_count = [], []\n",
        "for model_info in learner_list:\n",
        "  \n",
        "  if not model_info['fp_16']:\n",
        "    learn = load_learner(path_to_drive/model_info['folder'],model_info['name'],test=ImageList.from_folder(p_video))\n",
        "  else:\n",
        "    learn = load_learner(path_to_drive/model_info['folder'],model_info['name'],test=ImageList.from_folder(p_video)).to_fp32()\n",
        "  total_threshold, df_threshold = get_data_frames(learn, model_info['label_pos'], model_info['label_neg'])\n",
        "  print(model_info['name'], df_threshold.name.count())\n",
        "  data = get_data_bunch(df_threshold)\n",
        "  draw_on_learner(total_threshold, model_info['box-color'], model_info['label'])\n",
        "  model_stack.append(model_info['name'])\n",
        "  success_count.append(df_threshold.name.count())\n",
        "  learn.destroy()\n",
        "# \n",
        "for i in range(len(model_stack)):\n",
        "  print('Printed on {} images using {}'.format(success_count[i],model_stack[i]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-f45ec160856c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_drive\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'folder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtotal_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_threshold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_bunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-c89eb4b63ae1>\u001b[0m in \u001b[0;36mget_data_frames\u001b[0;34m(learn, label_pos, label_neg, threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mpreds_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpreds__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_pos\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;32melse\u001b[0m \u001b[0mlabel_neg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_type, activ, with_loss, n_batch, pbar)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(callbacks),\n\u001b[0;32m--> 339\u001b[0;31m                          activ=activ, loss_func=lf, n_batch=n_batch, pbar=pbar)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m\"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     res = [torch.cat(o).cpu() for o in\n\u001b[0;32m---> 44\u001b[0;31m            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mNoneReduceOnCPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1655\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m     )\n\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 7.91 GiB (GPU 0; 11.17 GiB total capacity; 9.56 GiB already allocated; 1.24 GiB free; 36.87 MiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BeU1-m7DBS6",
        "colab_type": "text"
      },
      "source": [
        "## Output Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQerd721_8Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "image_folder = str(p_video_out)+'/'\n",
        "video_name = 'full_video_0_95.avi'\n",
        "\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "heigth, width, layers = frame.shape\n",
        "#heigth, width, layers = int(height/2), int(width/2), layers\n",
        "ratio=width/heigth\n",
        "width=600\n",
        "heigth=int(width/ratio)\n",
        "\n",
        "#(width,height)=img.shape[1],img.shape[0]\n",
        "frs=25/frameRate\n",
        "video = cv2.VideoWriter(video_name, 0, frs,(width,heigth))\n",
        "\n",
        "for i in range(0,len(images)):\n",
        "    fname =\"frame%d.png\" % i;\n",
        "\n",
        "    full_fname=(image_folder+fname)\n",
        "\n",
        "    image=(cv2.imread(full_fname))\n",
        "    resize = cv2.resize(image,(width, heigth), interpolation = cv2.INTER_LINEAR)\n",
        "    video.write(resize)\n",
        "\n",
        "\n",
        "#for image in images:\n",
        "#    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWujWy8_7OwE",
        "colab_type": "code",
        "outputId": "85de6dde-8fa5-423a-a6e0-e849aedf68c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!zip -r /content/full_video.zip /content/full_video_0_95_hm.avi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/full_video_0_95_hm.avi (deflated 59%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yNHcWpsZ3LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}